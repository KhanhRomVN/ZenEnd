import time
import uuid
import json

ENABLE_FAKE_RESPONSE = False


def is_fake_mode_enabled() -> bool:
    return ENABLE_FAKE_RESPONSE


# ===== CUSTOM CONTENT =====
# üéØ S·ª¨A CONTENT ·ªû ƒê√ÇY ƒë·ªÉ test fake response
FAKE_CONTENT = """T√¥i ƒë√£ d·ª´ng server th√†nh c√¥ng. B√¢y gi·ªù t√¥i s·∫Ω c·∫≠p nh·∫≠t file c·∫•u h√¨nh cline_mcp_settings.json ƒë·ªÉ th√™m MCP server filesystem.
<write_to_file>
<path>../../../.config/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json
</path>
<content>
{
 "mcpServers": {
 "github.com/modelcontextprotocol/servers/tree/main/src/filesystem": {
 "command": "npx",
 "args": [
 "-y",
 "@modelcontextprotocol/server-filesystem",
 "/home/khanhromvn/Documents/Coding/ZenTab"
 ],
 "disabled": false,
 "autoApprove": []
 }
 }
}
</content>
<task_progress>
- [x] T·∫£i t√†i li·ªáu MCP
- [x] ƒê·ªçc file cline_mcp_settings.json hi·ªán t·∫°i
- [x] T·∫°o th∆∞ m·ª•c cho MCP server m·ªõi
- [x] C√†i ƒë·∫∑t MCP server filesystem
- [x] C·∫≠p nh·∫≠t c·∫•u h√¨nh cline_mcp_settings.json
- [ ] Ki·ªÉm tra v√† ch·ª©ng minh kh·∫£ nƒÉng c·ªßa server
</task_progress>
</write_to_file>"""


# ===== FAKE RESPONSE GENERATOR =====

async def generate_fake_response():
    # T·∫°o request_id ng·∫´u nhi√™n
    request_id = f"fake-{uuid.uuid4().hex[:16]}"
    
    # T·∫°o fake response theo OpenAI SSE format
    fake_response = {
        "id": f"chatcmpl-{request_id}",
        "object": "chat.completion.chunk",
        "created": int(time.time()),
        "model": "deepseek-chat",
        "choices": [{
            "index": 0,
            "delta": {
                "role": "assistant",
                "content": FAKE_CONTENT
            },
            "finish_reason": "stop",
            "logprobs": None
        }],
        "usage": {
            "prompt_tokens": 10000,
            "completion_tokens": len(FAKE_CONTENT.split()),
            "total_tokens": 1000 + len(FAKE_CONTENT.split())
        },
        "system_fingerprint": f"fp_{uuid.uuid4().hex[:8]}"
    }
    
    # Yield SSE formatted chunks
    yield f"data: {json.dumps(fake_response)}\n\n".encode('utf-8')
    yield "data: [DONE]\n\n".encode('utf-8')